{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be47d58a-e0c5-46c9-8a5c-3713c210a384",
   "metadata": {},
   "source": [
    "üìí 1. Personalized Offers Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a7526b7-2c5e-41ea-9ad0-f517807fd33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted 150 dummy offers into Redis\n",
      "üîé Top 5 offers for profile [city=Mumbai, gender=male, category=travel]:\n",
      "  - City: Mumbai, Gender: male, Category: travel, Score: -3.57627868652e-07\n",
      "  - City: Mumbai, Gender: male, Category: travel, Score: -3.57627868652e-07\n",
      "  - City: Mumbai, Gender: female, Category: travel, Score: 0.207103610039\n",
      "  - City: Mumbai, Gender: female, Category: fashion, Score: 0.21957886219\n",
      "  - City: Mumbai, Gender: female, Category: fashion, Score: 0.21957886219\n"
     ]
    }
   ],
   "source": [
    "import redis, numpy as np, json, hashlib\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import VectorField, TextField, TagField\n",
    "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# Schema for vector + tags\n",
    "schema = [\n",
    "    TextField(\"$.category\", as_name=\"category\"),\n",
    "    TagField(\"$.city\", as_name=\"city\"),\n",
    "    TagField(\"$.gender\", as_name=\"gender\"),\n",
    "    VectorField(\"$.embedding\", \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": 384,\n",
    "        \"DISTANCE_METRIC\": \"COSINE\"\n",
    "    }, as_name=\"embedding\")\n",
    "]\n",
    "\n",
    "INDEX_NAME = \"idx:offers\"\n",
    "\n",
    "# Drop index if exists\n",
    "try:\n",
    "    r.ft(INDEX_NAME).dropindex(delete_documents=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create index\n",
    "r.ft(INDEX_NAME).create_index(\n",
    "    schema, definition=IndexDefinition(prefix=[\"offer:\"], index_type=IndexType.JSON)\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Helper: deterministic embedding generator\n",
    "# based on city+gender+category string\n",
    "# --------------------------------------\n",
    "def generate_embedding(city, gender, category, dim=384):\n",
    "    seed_str = f\"{city}_{gender}_{category}\"\n",
    "    seed = int(hashlib.md5(seed_str.encode()).hexdigest(), 16) % (2**32)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.random(dim).tolist()\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Function to generate dummy offers\n",
    "# --------------------------------------\n",
    "def generate_dummy_offers(num_offers: int = 10):\n",
    "    cities = [\"Mumbai\", \"Delhi\", \"Bangalore\", \"Chennai\", \"Hyderabad\"]\n",
    "    genders = [\"male\", \"female\"]\n",
    "    categories = [\"lifestyle\", \"fashion\", \"travel\", \"electronics\", \"dining\", \"grocery\"]\n",
    "\n",
    "    for i in range(1, num_offers + 1):\n",
    "        city = np.random.choice(cities)\n",
    "        gender = np.random.choice(genders)\n",
    "        category = np.random.choice(categories)\n",
    "\n",
    "        offer_id = f\"offer:{i:03d}\"\n",
    "        offer_data = {\n",
    "            \"city\": city,\n",
    "            \"gender\": gender,\n",
    "            \"category\": category,\n",
    "            \"embedding\": generate_embedding(city, gender, category)\n",
    "        }\n",
    "        r.execute_command(\"JSON.SET\", offer_id, \"$\", json.dumps(offer_data))\n",
    "\n",
    "    print(f\"‚úÖ Inserted {num_offers} dummy offers into Redis\")\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Function to query offers by user profile\n",
    "# --------------------------------------\n",
    "def query_offers(user_city, user_gender, user_category, k: int = 3):\n",
    "    # Create query vector from profile\n",
    "    user_vector = np.array(\n",
    "        generate_embedding(user_city, user_gender, user_category),\n",
    "        dtype=np.float32\n",
    "    ).tobytes()\n",
    "\n",
    "    q = (\n",
    "        Query(f\"*=>[KNN {k} @embedding $vec AS score]\")\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"city\", \"gender\", \"category\", \"score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "\n",
    "    results = r.ft(INDEX_NAME).search(q, query_params={\"vec\": user_vector})\n",
    "    print(f\"üîé Top {k} offers for profile [city={user_city}, gender={user_gender}, category={user_category}]:\")\n",
    "    for doc in results.docs:\n",
    "        print(f\"  - City: {doc.city}, Gender: {doc.gender}, Category: {doc.category}, Score: {doc.score}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Main demo\n",
    "# --------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Generate 15 dummy offers\n",
    "    generate_dummy_offers(150)\n",
    "\n",
    "    # Step 2: Simulate a user profile\n",
    "    user_city = \"Mumbai\"\n",
    "    user_gender = \"male\"\n",
    "    user_category = \"travel\"\n",
    "\n",
    "    # Step 3: Query top 5 relevant offers\n",
    "    query_offers(user_city, user_gender, user_category, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbdd209-e234-44b2-bb4b-f3f648e0abfe",
   "metadata": {},
   "source": [
    "üìí 2. Fraud Detection Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a243f77c-9391-4460-a41a-d01f9f0ebfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dummy transactions generated.\n",
      "\n",
      "üîç Evaluating transaction...\n",
      "Verdict: LIKELY FRAUD\n",
      "Fraud Risk Score: 85.0%\n",
      "\n",
      "Top Neighbors:\n",
      "TxnID=txn:1083, Amount=10000, UserCity=Delhi, TxnCity=London, Fraud=YES, Score=0.36502790451\n",
      "TxnID=txn:1061, Amount=10000, UserCity=Mumbai, TxnCity=New York, Fraud=YES, Score=0.365520834923\n",
      "TxnID=txn:1056, Amount=25000.5, UserCity=London, TxnCity=Mumbai, Fraud=YES, Score=0.368060588837\n",
      "TxnID=txn:1090, Amount=25000.5, UserCity=Mumbai, TxnCity=London, Fraud=YES, Score=0.374779224396\n",
      "TxnID=txn:1078, Amount=75000.75, UserCity=Singapore, TxnCity=New York, Fraud=YES, Score=0.388195574284\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import redis, numpy as np, json, random, time\n",
    "from redis.commands.search.field import VectorField, TextField, NumericField, TagField\n",
    "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "# -----------------------------\n",
    "# Redis Connection\n",
    "# -----------------------------\n",
    "r = redis.Redis(host=\"localhost\", port=6379, decode_responses=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Constants\n",
    "# -----------------------------\n",
    "INDEX_NAME = \"idx:txns\"\n",
    "VECTOR_DIM = 128   # embedding size\n",
    "\n",
    "# -----------------------------\n",
    "# Drop and recreate index\n",
    "# -----------------------------\n",
    "try:\n",
    "    r.ft(INDEX_NAME).dropindex(delete_documents=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "schema = (\n",
    "    TextField(\"$.txn_id\", as_name=\"txn_id\"),\n",
    "    TextField(\"$.user_id\", as_name=\"user_id\"),\n",
    "    TagField(\"$.user_city\", as_name=\"user_city\"),\n",
    "    TagField(\"$.txn_city\", as_name=\"txn_city\"),\n",
    "    TagField(\"$.gender\", as_name=\"gender\"),\n",
    "    TextField(\"$.device\", as_name=\"device\"),\n",
    "    TextField(\"$.ip_address\", as_name=\"ip_address\"),\n",
    "    NumericField(\"$.amount\", as_name=\"amount\"),\n",
    "    TagField(\"$.txn_type\", as_name=\"txn_type\"),\n",
    "    TagField(\"$.is_fraud\", as_name=\"is_fraud\"),\n",
    "    VectorField(\"$.embedding\", \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": \"COSINE\",\n",
    "        \"INITIAL_CAP\": 1000\n",
    "    }, as_name=\"embedding\")\n",
    ")\n",
    "\n",
    "definition = IndexDefinition(prefix=[\"txn:\"], index_type=IndexType.JSON)\n",
    "r.ft(INDEX_NAME).create_index(fields=schema, definition=definition)\n",
    "\n",
    "# -----------------------------\n",
    "# Embedding Creator\n",
    "# -----------------------------\n",
    "def create_embedding(txn, dim=128):\n",
    "    \"\"\"\n",
    "    Generate a meaningful embedding from transaction metadata.\n",
    "    \"\"\"\n",
    "    vec = np.zeros(dim, dtype=np.float32)\n",
    "\n",
    "    # 1. City mismatch\n",
    "    vec[0] = 1.0 if txn[\"user_city\"] != txn[\"txn_city\"] else 0.0\n",
    "\n",
    "    # 2. Amount scaled (assume 100k max)\n",
    "    vec[1] = min(txn[\"amount\"] / 100000.0, 1.0)\n",
    "\n",
    "    # 3. Transaction type (one-hot)\n",
    "    txn_type_map = {\"POS\": 2, \"ONLINE\": 3, \"ATM\": 4, \"TRANSFER\": 5}\n",
    "    if txn[\"txn_type\"] in txn_type_map:\n",
    "        vec[txn_type_map[txn[\"txn_type\"]]] = 1.0\n",
    "\n",
    "    # 4. Device encoding (simplified grouping)\n",
    "    device_map = {\n",
    "        \"iPhone\": 6, \"Samsung\": 7, \"Windows\": 8,\n",
    "        \"Macbook\": 9, \"iPad\": 10, \"Pixel\": 11\n",
    "    }\n",
    "    for k, idx in device_map.items():\n",
    "        if k.lower() in txn[\"device\"].lower():\n",
    "            vec[idx] = 1.0\n",
    "\n",
    "    # 5. Gender\n",
    "    gender_map = {\"M\": 12, \"F\": 13, \"O\": 14}\n",
    "    if txn[\"gender\"] in gender_map:\n",
    "        vec[gender_map[txn[\"gender\"]]] = 1.0\n",
    "\n",
    "    # 6. Fraud flag (historical)\n",
    "    if txn[\"is_fraud\"] == \"YES\":\n",
    "        vec[15] = 1.0\n",
    "\n",
    "    # 7. Add small noise for realism\n",
    "    noise = np.random.normal(0, 0.05, dim-16).astype(np.float32)\n",
    "    vec[16:] = noise\n",
    "\n",
    "    return [float(x) for x in vec]\n",
    "\n",
    "# -----------------------------\n",
    "# Dummy Data Generator\n",
    "# -----------------------------\n",
    "def random_ip():\n",
    "    return \".\".join(str(random.randint(0, 255)) for _ in range(4))\n",
    "\n",
    "def random_device():\n",
    "    return random.choice([\"iPhone 14\", \"Samsung S22\", \"Windows Laptop\", \n",
    "                          \"Macbook Pro\", \"iPad\", \"Pixel 7\"])\n",
    "\n",
    "def random_txn_type():\n",
    "    return random.choice([\"POS\", \"ONLINE\", \"ATM\", \"TRANSFER\"])\n",
    "\n",
    "def generate_dummy_transactions(n=50):\n",
    "    cities = [\"Mumbai\", \"Delhi\", \"London\", \"New York\", \"Singapore\"]\n",
    "    genders = [\"M\", \"F\", \"O\"]\n",
    "\n",
    "    for i in range(n):\n",
    "        txn_id = f\"txn:{1000+i}\"\n",
    "        user_id = f\"user_{random.randint(1, 20)}\"\n",
    "        user_city = random.choice(cities)\n",
    "        txn_city = random.choice(cities)   # can differ\n",
    "        gender = random.choice(genders)\n",
    "        device = random_device()\n",
    "        ip_address = random_ip()\n",
    "        txn_type = random_txn_type()\n",
    "\n",
    "        # Fraud logic\n",
    "        is_fraud = False\n",
    "        if random.random() < 0.25:  # baseline fraud probability\n",
    "            is_fraud = True\n",
    "        if user_city != txn_city:   # suspicious mismatch\n",
    "            is_fraud = True\n",
    "\n",
    "        if is_fraud:\n",
    "            amount = random.choice([4999.99, 10000.0, 25000.5, 75000.75])\n",
    "        else:\n",
    "            amount = round(random.uniform(10.0, 5000.0), 2)\n",
    "\n",
    "        txn_data = {\n",
    "            \"txn_id\": txn_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"user_city\": user_city,\n",
    "            \"txn_city\": txn_city,\n",
    "            \"gender\": gender,\n",
    "            \"device\": device,\n",
    "            \"ip_address\": ip_address,\n",
    "            \"txn_type\": txn_type,\n",
    "            \"amount\": amount,\n",
    "            \"timestamp\": int(time.time()),\n",
    "            \"is_fraud\": \"YES\" if is_fraud else \"NO\",\n",
    "        }\n",
    "\n",
    "        # meaningful embedding\n",
    "        txn_data[\"embedding\"] = create_embedding(txn_data, VECTOR_DIM)\n",
    "\n",
    "        r.execute_command(\"JSON.SET\", txn_id, \"$\", json.dumps(txn_data))\n",
    "\n",
    "# -----------------------------\n",
    "# Query Similar Transactions\n",
    "# -----------------------------\n",
    "def query_similar_transactions(input_txn, k=5, threshold=0.6):\n",
    "    query_vector = np.array(input_txn[\"embedding\"], dtype=np.float32).tobytes()\n",
    "\n",
    "    q = (\n",
    "        Query(\"@txn_type:{%s} => [KNN %d @embedding $vec AS score]\" % (input_txn[\"txn_type\"], k))\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"txn_id\", \"amount\", \"user_city\", \"txn_city\", \"is_fraud\", \"score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "\n",
    "    results = r.ft(INDEX_NAME).search(q, query_params={\"vec\": query_vector})\n",
    "\n",
    "    # ---------------------------\n",
    "    # Fraud Risk Calculation\n",
    "    # ---------------------------\n",
    "    fraud_neighbors = 0\n",
    "    for doc in results.docs:\n",
    "        if doc.is_fraud == \"YES\":\n",
    "            fraud_neighbors += 1\n",
    "    fraud_ratio = fraud_neighbors / max(1, len(results.docs))\n",
    "\n",
    "    # city mismatch\n",
    "    city_mismatch = 1.0 if input_txn[\"user_city\"] != input_txn[\"txn_city\"] else 0.0\n",
    "\n",
    "    # high amount anomaly\n",
    "    amount_anomaly = 1.0 if input_txn[\"amount\"] > 5000 else 0.0\n",
    "\n",
    "    # final fraud risk score\n",
    "    fraud_score = (0.6 * fraud_ratio) + (0.25 * city_mismatch) + (0.15 * amount_anomaly)\n",
    "\n",
    "    verdict = \"LIKELY FRAUD\" if fraud_score >= threshold else \"LIKELY LEGIT\"\n",
    "\n",
    "    return {\n",
    "        \"neighbors\": results.docs,\n",
    "        \"fraud_score\": round(fraud_score * 100, 2),\n",
    "        \"verdict\": verdict\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample data\n",
    "    generate_dummy_transactions(100)\n",
    "    print(\"‚úÖ Dummy transactions generated.\")\n",
    "\n",
    "    # Create a test input transaction\n",
    "    test_txn = {\n",
    "        \"txn_id\": \"txn:test\",\n",
    "        \"user_id\": \"user_999\",\n",
    "        \"user_city\": \"Mumbai\",   # expected home city\n",
    "        \"txn_city\": \"Delhi\",    # different ‚Üí suspicious\n",
    "        \"gender\": \"M\",\n",
    "        \"device\": \"iPhone 14\",\n",
    "        \"ip_address\": \"192.168.1.25\",\n",
    "        \"txn_type\": \"ONLINE\",\n",
    "        \"amount\": 5000.0,\n",
    "        \"timestamp\": int(time.time()),\n",
    "        \"is_fraud\": \"UNKNOWN\",\n",
    "    }\n",
    "\n",
    "    # generate embedding for the input txn\n",
    "    test_txn[\"embedding\"] = create_embedding(test_txn, VECTOR_DIM)\n",
    "    print(\"\\nüîç Evaluating transaction...\")\n",
    "    result = query_similar_transactions(test_txn, k=5)\n",
    "\n",
    "    print(f\"Verdict: {result['verdict']}\")\n",
    "    print(f\"Fraud Risk Score: {result['fraud_score']}%\")\n",
    "\n",
    "    print(\"\\nTop Neighbors:\")\n",
    "    for doc in result[\"neighbors\"]:\n",
    "        print(f\"TxnID={doc.txn_id}, Amount={doc.amount}, \"\n",
    "              f\"UserCity={doc.user_city}, TxnCity={doc.txn_city}, \"\n",
    "              f\"Fraud={doc.is_fraud}, Score={doc.score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d78f9-c144-4ad0-9726-1091216fb1ee",
   "metadata": {},
   "source": [
    "üìí 3. Customer Support Matching Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5257ddb-7319-4aa4-810d-d1e981e7e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Question: How to reset my credit card PIN?\n",
      "Matched Q: How to reset my credit card PIN?\n",
      "Answer: You can reset your PIN from the mobile app under 'Card Settings'.\n",
      "Score: -2.38418579102e-07\n",
      "\n",
      "Matched Q: How to block my card?\n",
      "Answer: You can block your card instantly via mobile app or by calling customer support.\n",
      "Score: 0.250017523766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import redis, numpy as np, json, hashlib\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import VectorField, TextField\n",
    "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# Parameters\n",
    "INDEX_NAME = \"idx:qna\"\n",
    "VECTOR_DIM = 384  # embedding dimension\n",
    "\n",
    "# Helper: Create deterministic embedding from text\n",
    "def text_to_embedding(text, dim=VECTOR_DIM):\n",
    "    \"\"\"Convert text into a deterministic pseudo-embedding using hashing.\"\"\"\n",
    "    h = hashlib.sha256(text.encode(\"utf-8\")).digest()\n",
    "    np.random.seed(int.from_bytes(h[:4], \"little\"))  # deterministic seed from hash\n",
    "    return np.random.rand(dim).astype(np.float32).tolist()\n",
    "\n",
    "# Reset index if exists\n",
    "try:\n",
    "    r.ft(INDEX_NAME).dropindex(delete_documents=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Define schema\n",
    "schema = (\n",
    "    TextField(\"$.question\", as_name=\"question\"),\n",
    "    TextField(\"$.answer\", as_name=\"answer\"),\n",
    "    VectorField(\"$.embedding\", \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": \"COSINE\",\n",
    "        \"INITIAL_CAP\": 1000\n",
    "    }, as_name=\"embedding\")\n",
    ")\n",
    "definition = IndexDefinition(prefix=[\"qna:\"], index_type=IndexType.JSON)\n",
    "\n",
    "# Create index\n",
    "r.ft(INDEX_NAME).create_index(fields=schema, definition=definition)\n",
    "\n",
    "# Function: Generate dummy Q&A pairs\n",
    "def generate_dummy_qna():\n",
    "    qna_data = [\n",
    "        (\"How to block my card?\", \"You can block your card instantly via mobile app or by calling customer support.\"),\n",
    "        (\"How to increase my credit card limit?\", \"Submit a request via internet banking or mobile app, subject to eligibility.\"),\n",
    "        (\"How to reset my credit card PIN?\", \"You can reset your PIN from the mobile app under 'Card Settings'.\"),\n",
    "        (\"How to check my reward points?\", \"Reward points can be checked via your monthly statement or app dashboard.\"),\n",
    "        (\"What should I do if my card is lost?\", \"Immediately block your card and request a replacement from customer support.\"),\n",
    "        (\"How can I dispute a fraudulent transaction?\", \"Raise a dispute through mobile app or helpline within 30 days of the transaction.\"),\n",
    "        (\"How to update my registered mobile number?\", \"Update mobile number by visiting the nearest branch or via internet banking.\"),\n",
    "    ]\n",
    "    \n",
    "    for i, (q, a) in enumerate(qna_data, start=1):\n",
    "        qid = f\"qna:{i:02d}\"\n",
    "        qa_doc = {\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"embedding\": text_to_embedding(q)\n",
    "        }\n",
    "        r.execute_command(\"JSON.SET\", qid, \"$\", json.dumps(qa_doc))\n",
    "\n",
    "# Function: Query for most similar Q&A\n",
    "def query_similar_question(sample_question, top_k=2):\n",
    "    query_vector = np.array(text_to_embedding(sample_question), dtype=np.float32).tobytes()\n",
    "    q = (\n",
    "        Query(f\"*=>[KNN {top_k} @embedding $vec AS score]\")\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"question\", \"answer\", \"score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "    results = r.ft(INDEX_NAME).search(q, query_params={\"vec\": query_vector})\n",
    "    return results\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate dummy Q&A set\n",
    "    generate_dummy_qna()\n",
    "    \n",
    "    # Run a sample query\n",
    "    user_question = \"I lost my credit card, what should I do?\"\n",
    "    user_question = \"I want to block my card?\"\n",
    "    user_question = \"Where can I see my reward points\"\n",
    "    user_question = \"How to reset my credit card PIN?\"\n",
    "    results = query_similar_question(user_question, top_k=2)\n",
    "    \n",
    "    print(\"User Question:\", user_question)\n",
    "    for doc in results.docs:\n",
    "        print(f\"Matched Q: {doc.question}\\nAnswer: {doc.answer}\\nScore: {doc.score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d22fa-0ac7-42f7-95c7-d4eb2b5d8491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
